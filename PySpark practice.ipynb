{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8534f9e0-82b5-4037-8f7a-a039d1066995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad744e93-b41b-4a51-bd0c-856b657babc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a217c6-8c4f-4380-b399-c23b2b3eb552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3a5ba7-283c-4714-a372-6710ef7175f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.sql('''select 'spark' as hello ''')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b961c8ad-a7c2-4626-befc-ddfbf59e7214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-3B65H5O:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a64091-5a87-459d-bb20-603629005bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book = spark.read.text(\"1342-0.txt\")\n",
    "book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e56577b6-8072-4a4f-a232-3fd0d1accbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.printSchema() #schema of the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0174bbcf-670c-453c-8c96-c05cd453fb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        property\n",
       "\u001b[1;31mString form:\u001b[0m <property object at 0x0000026CFE7273D0>\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Returns a :class:`DataFrameReader` that can be used to read data\n",
       "in as a :class:`DataFrame`.\n",
       "\n",
       ".. versionadded:: 2.0.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       ":class:`DataFrameReader`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.read?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e59672-49a0-41b1-84ea-11d4160873a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|The Project Guten...|\n",
      "|                    |\n",
      "|This eBook is for...|\n",
      "|almost no restric...|\n",
      "|re-use it under t...|\n",
      "|with this eBook o...|\n",
      "|                    |\n",
      "|                    |\n",
      "|Title: Pride and ...|\n",
      "|                    |\n",
      "| Author: Jane Austen|\n",
      "|                    |\n",
      "|Posting Date: Aug...|\n",
      "|Release Date: Jun...|\n",
      "|Last Updated: Mar...|\n",
      "|                    |\n",
      "|   Language: English|\n",
      "|                    |\n",
      "|Character set enc...|\n",
      "|                    |\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.show() #show book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f310b19-2afe-4db3-942e-73668fb8ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                             value|\n",
      "+--------------------------------------------------+\n",
      "|The Project Gutenberg EBook of Pride and Prejud...|\n",
      "|                                                  |\n",
      "|This eBook is for the use of anyone anywhere at...|\n",
      "|almost no restrictions whatsoever.  You may cop...|\n",
      "|re-use it under the terms of the Project Gutenb...|\n",
      "|    with this eBook or online at www.gutenberg.org|\n",
      "|                                                  |\n",
      "|                                                  |\n",
      "|                        Title: Pride and Prejudice|\n",
      "|                                                  |\n",
      "+--------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.show(10, truncate=50)#show book wider with fewer lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5734e863-84fd-4570-a3c9-1fc5e15a72ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                line|\n",
      "+--------------------+\n",
      "|[The, Project, Gu...|\n",
      "|                  []|\n",
      "|[This, eBook, is,...|\n",
      "|[almost, no, rest...|\n",
      "|[re-use, it, unde...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "lines = book.select(split(book.value, \" \").alias(\"line\"))\n",
    "lines.show(5) #show book line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71a25b35-f84a-402c-b746-ef797997bcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(book.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b3aab77-3b3e-4569-b308-a22f278440ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "book.select(book.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0f516d3-4f66-42c7-a169-e42d2c27dc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(book[\"value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dbe6eb8-26b8-4ac0-be1d-cb0cf71c339a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(col(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c369c275-378c-47f6-b5bc-7ced9089410b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[split(value,  , -1): array<string>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split\n",
    "lines = book.select(split(col(\"value\"), \" \"))\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90790f5d-96a9-4144-939c-2996f1075ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- split(value,  , -1): array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.select(split(col(\"value\"), \" \")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44100583-0931-4a48-bb6b-327dbc69b9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[line: array<string>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = book.select(split(book.value, \" \").alias(\"line\"))\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2d4149c-d684-410a-b640-ef39c309c087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|       The|\n",
      "|   Project|\n",
      "| Gutenberg|\n",
      "|     EBook|\n",
      "|        of|\n",
      "|     Pride|\n",
      "|       and|\n",
      "|Prejudice,|\n",
      "|        by|\n",
      "|      Jane|\n",
      "|    Austen|\n",
      "|          |\n",
      "|      This|\n",
      "|     eBook|\n",
      "|        is|\n",
      "+----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "words = lines.select(explode(col(\"line\")).alias(\"word\"))\n",
    "words.show(15) #show a word for every row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80083651-b02d-456b-93cb-1c5c6ddb8645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|word_lower|\n",
      "+----------+\n",
      "|       the|\n",
      "|   project|\n",
      "| gutenberg|\n",
      "|     ebook|\n",
      "|        of|\n",
      "|     pride|\n",
      "|       and|\n",
      "|prejudice,|\n",
      "|        by|\n",
      "|      jane|\n",
      "|    austen|\n",
      "|          |\n",
      "|      this|\n",
      "|     ebook|\n",
      "|        is|\n",
      "|       for|\n",
      "|       the|\n",
      "|       use|\n",
      "|        of|\n",
      "|    anyone|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "words_lower = words.select(lower(col(\"word\")).alias(\"word_lower\"))\n",
    "words_lower.show()#show lowercase word for every row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53a7f9a1-773c-4613-8b70-1975b5a9c8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|    pride|\n",
      "|      and|\n",
      "|prejudice|\n",
      "|       by|\n",
      "|     jane|\n",
      "|   austen|\n",
      "|         |\n",
      "|     this|\n",
      "|    ebook|\n",
      "|       is|\n",
      "|      for|\n",
      "|      the|\n",
      "|      use|\n",
      "|       of|\n",
      "|   anyone|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "words_clean = words_lower.select(    regexp_extract(col(\"word_lower\"), \"[a-z]*\", 0).alias(\"word\")  )\n",
    "words_clean.show() #show lowercase word for every row with all regular expressions gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e55c25f-44c8-40e9-8517-90550679c785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|    pride|\n",
      "|      and|\n",
      "|prejudice|\n",
      "|       by|\n",
      "|     jane|\n",
      "|   austen|\n",
      "|     this|\n",
      "|    ebook|\n",
      "|       is|\n",
      "|      for|\n",
      "|      the|\n",
      "|      use|\n",
      "|       of|\n",
      "|   anyone|\n",
      "| anywhere|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_nonull = words_clean.where(col(\"word\") != \"\")\n",
    "words_nonull.show() #remove null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4820990b-4af3-490e-a331-50003035cf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         word|count|\n",
      "+-------------+-----+\n",
      "|       online|    4|\n",
      "|         some|  203|\n",
      "|        still|   72|\n",
      "|          few|   72|\n",
      "|         hope|  122|\n",
      "|        those|   60|\n",
      "|     cautious|    4|\n",
      "|    imitation|    1|\n",
      "|          art|    3|\n",
      "|      solaced|    1|\n",
      "|       poetry|    2|\n",
      "|    arguments|    5|\n",
      "| premeditated|    1|\n",
      "|      elevate|    1|\n",
      "|       doubts|    2|\n",
      "|    destitute|    1|\n",
      "|    solemnity|    5|\n",
      "|   lieutenant|    1|\n",
      "|gratification|    1|\n",
      "|    connected|   14|\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groups = words_nonull.groupby(col(\"word\"))\n",
    "results = words_nonull.groupby(col(\"word\")).count()\n",
    "results.show()#show word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22c82261-5473-48e5-bd95-67b059e0dac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the| 4480|\n",
      "|  to| 4218|\n",
      "|  of| 3711|\n",
      "| and| 3504|\n",
      "| her| 2199|\n",
      "|   a| 1982|\n",
      "|  in| 1909|\n",
      "| was| 1838|\n",
      "|   i| 1750|\n",
      "| she| 1668|\n",
      "+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.orderBy(\"count\", ascending=False).show(10) #sort by word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78369eec-007e-4922-9ca5-4f0c8f0c05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.coalesce(1).write.csv(\"./results_single_partition.csv\") #put all word count in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10f022b3-c4f1-456b-a6cf-5e8764d7c626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the| 4480|\n",
      "|  to| 4218|\n",
      "|  of| 3711|\n",
      "| and| 3504|\n",
      "| her| 2199|\n",
      "|   a| 1982|\n",
      "|  in| 1909|\n",
      "| was| 1838|\n",
      "|   i| 1749|\n",
      "| she| 1668|\n",
      "|that| 1487|\n",
      "|  it| 1482|\n",
      "| not| 1427|\n",
      "| you| 1300|\n",
      "|  he| 1296|\n",
      "|  be| 1257|\n",
      "| his| 1247|\n",
      "|  as| 1174|\n",
      "| had| 1170|\n",
      "|with| 1092|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F #put everything in one place\n",
    "results = (    \n",
    "    spark.read.text(\"1342-0.txt\")    \n",
    "    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))    \n",
    "    .select(F.explode(F.col(\"line\")).alias(\"word\"))    \n",
    "    .select(F.lower(F.col(\"word\")).alias(\"word\"))    \n",
    "    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))    \n",
    "    .where(F.col(\"word\") != \"\")    \n",
    "    .groupby(\"word\")    \n",
    "    .count()\n",
    ")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32483ca5-5f04-4ad1-97db-e84f59cd6ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-3B65H5O:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x26cfe74ef20>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession #create own spark session\n",
    "spark = (SparkSession.builder                     \n",
    "         .appName(\"Counting word occurences from a book.\")                     \n",
    "         .getOrCreate())\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "773e5578-5dbd-4035-bbf9-550420dbf39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the|38895|\n",
      "| and|23919|\n",
      "|  of|21199|\n",
      "|  to|20526|\n",
      "|   a|14464|\n",
      "|   i|13973|\n",
      "|  in|12777|\n",
      "|that| 9623|\n",
      "|  it| 9099|\n",
      "| was| 8920|\n",
      "| her| 7923|\n",
      "|  my| 7385|\n",
      "| his| 6642|\n",
      "|with| 6575|\n",
      "|  he| 6444|\n",
      "|  as| 6439|\n",
      "| you| 6295|\n",
      "| had| 5718|\n",
      "| she| 5617|\n",
      "| for| 5425|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = (    \n",
    "    spark.read.text(\"*.txt\")    \n",
    "    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))    \n",
    "    .select(F.explode(F.col(\"line\")).alias(\"word\"))    \n",
    "    .select(F.lower(F.col(\"word\")).alias(\"word\"))    \n",
    "    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))    \n",
    "    .where(F.col(\"word\") != \"\")    \n",
    "    .groupby(\"word\")    \n",
    "    .count()\n",
    ")\n",
    "results.orderBy(\"count\", ascending=False).show()# for all txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2461062-91a5-4f66-aff7-2fb6a323c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b24b7f7-5f5f-4389-9b5f-8085ee32ee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51015ad-c352-4545-945a-5d846a87b6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
